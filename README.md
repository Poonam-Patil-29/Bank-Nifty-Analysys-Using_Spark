# Bank-Nifty-Analysys-Using_Spark
### About Project :
This project is aimed at developing a powerful PySpark analysis on bank nifty dataset. The dataset contains more than 5550 records. The data contains information such as - date, open,close,high,range_HL,range_OL,type etc. The project aims to analyze the historical data of Bank Nifty, including stock prices and other financial metrics, using Spark's powerful analytics capabilities.The project's ultimate goal is to create a robust and accurate predictive model that can assist investors and traders in making informed decisions regarding their investments in the banking sector.
                  
### REQUIREMENTS :

1. Functionality should reflect the below user stories.
2. Data is imported in a CSV File formate.
3. Data Access is performed through the use of Csv file using file path with Sparkseassion.
4. Data functions is done using Sparksession and RDDs in spark Framework.
5. Driver code and functionalities is done using python.

TECHONOLOGIES USED ;
* Language                  :   Python
* Environment               :   Jupyter Notebook
* Modules and Libraries     :   Pyspark, matplot, seaborn, Findspark, Pandas

### Analysis Options :
* 1.To view all data in dataset ')
* 2. To check how many rows u want to fetch')
* 3. To check count of weekdays')
* 4. To check minimum values')
* 5. To check maximum values')
* 6. To sort open and close ascending order')    
* 7. To check details between given dates')
* 8. To check the average  according to its type')
* 9. To check nity closing between range')
* 10. To check count of according to its types')
* 11. To check data on weekley bases')
* 12. To count week days')
* 13. To check nifty prediction')
* 14. To check visualization')
* 15. For Logout')
